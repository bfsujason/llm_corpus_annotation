{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86d6e8a-ba20-4c13-ae5f-36803b8d2605",
   "metadata": {},
   "source": [
    "#### **1. 导入模块**\n",
    "\n",
    "导入 Python 标准库和本项目自定义库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb93fcb-bed0-412f-8e4c-df010fa8e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 将上级目录加入系统路径\n",
    "# 以便导入项目自定义库\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# 自定义库\n",
    "from src.llm_client import LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02c254-784a-44da-aa6a-88a115292530",
   "metadata": {},
   "source": [
    "#### **2. 加载模型**\n",
    "\n",
    "加载大模型 API 接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7fbb4b-054a-4843-8d4d-212917c7e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM API 接口加载完毕！\n"
     ]
    }
   ],
   "source": [
    "# 模型名称\n",
    "# 可选模型：\n",
    "# 大模型：kimi-k2.5 | glm-5 | deepseek-v3.2 | qwen3-max\n",
    "\n",
    "model = 'kimi-k2.5'\n",
    "\n",
    "# 采样温度系数\n",
    "# 控制生成结果的多样性\n",
    "# 取值越高，生成结果更多样\n",
    "# 反之，生成结果更确定\n",
    "# 取值范围：[0, 2)\n",
    "# 默认系数：0.1\n",
    "\n",
    "temperature = 0.1\n",
    "\n",
    "# 是否开启思考模式\n",
    "# 若开启：enable_thinking =True\n",
    "# 模型会输出完整推理过程\n",
    "# 生成更长文本，消耗更多 Token\n",
    "# 默认模式：不开启\n",
    "\n",
    "enable_thinking = False\n",
    "\n",
    "# 初始化大模型 API 接口\n",
    "# 登录阿里云百炼平台：https://bailian.console.aliyun.com/\n",
    "# 申请调用大模型服务的 API-Key\n",
    "# 并在 config 文件中设置 LLM_API_KEY=sk-********\n",
    "# 新注册用户可免费调用部分模型的 API\n",
    "# 登录后在模型服务页面查看免费模型列表\n",
    "\n",
    "client = LLMClient(\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    enable_thinking=enable_thinking,\n",
    ")\n",
    "print('LLM API 接口加载完毕！')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0a962-d493-45f0-a49c-5b39320791d1",
   "metadata": {},
   "source": [
    "#### **3. 汉语分词**\n",
    "\n",
    "大模型汉语分词：文本格式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d37c5d7-153f-438c-ad11-ad7faa56c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 汉语分词提示词：文本格式输出 ===\n",
    "\n",
    "# 可替换提示词中的中文文本\n",
    "# 测试中文分词效果\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a professional corpus linguist specialized in Chinese tokenization.\n",
    "\n",
    "Your task is to tokenize the given text.\n",
    "\n",
    "Text: 北风如刀，满地冰霜。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b12846-ef30-4cf2-b7fc-ca497170d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ll tokenize this classical Chinese text, analyzing it linguistically.\\n\\n## Tokenization Result\\n\\n| Token | POS/Category | Notes |\\n|-------|-------------|-------|\\n| 北风 | Noun (NP) | Compound noun: \"north wind\" |\\n| 如 | Verb/Simile marker | \"like, as\" — comparative verb |\\n| 刀 | Noun | \"knife/blade\" — object of simile |\\n| ， | Punctuation | Comma |\\n| 满地 | Adverbial phrase (Loc+NP) | \"full ground\" = everywhere on the ground |\\n| 冰霜 | Noun (NP) | Compound noun: \"frost and ice\" |\\n| 。 | Punctuation | Period |\\n\\n---\\n\\n## Analysis\\n\\n**Sentence structure:**\\n- **Clause 1:** 北风如刀 — Subject-Predicate with simile (明喻)\\n  - [NP 北风] + [V 如] + [NP 刀]\\n  - \"The north wind is like a knife\"\\n\\n- **Clause 2:** 满地冰霜 — Locative-topic construction\\n  - [AdvP 满地] + [NP 冰霜]\\n  - \"(There is) frost and ice all over the ground\"\\n\\n**Poetic features:** Parallel 4-character clauses (四字句), typical of classical Chinese regulated verse. The comma splits two imagistic descriptions forming a couplet-like structure.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 调用大模型 API：开始分词 ===\n",
    "\n",
    "# --- 注意 ---\n",
    "# 为节省 API 调用成本\n",
    "# 大模型生成内容保存于本地缓存 data/llm_cache\n",
    "# 完成首次调用后，再次调用只需从本地数据库读取生成结果\n",
    "\n",
    "# 若需测试 API 连接是否正常\n",
    "# 可修改提示词后，重新标注\n",
    "\n",
    "# 输出文本格式的分词结果\n",
    "\n",
    "client.get_response(prompt=prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
