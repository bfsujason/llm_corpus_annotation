{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fb5cd8-2ed0-4ea9-9920-dafb8d5a9445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T18:09:08.740591Z",
     "iopub.status.busy": "2026-01-17T18:09:08.740376Z",
     "iopub.status.idle": "2026-01-17T18:09:08.745757Z",
     "shell.execute_reply": "2026-01-17T18:09:08.745027Z",
     "shell.execute_reply.started": "2026-01-17T18:09:08.740574Z"
    },
    "tags": []
   },
   "source": [
    "#### **1. 导入模块**\n",
    "\n",
    "导入 Python 标准库和本项目自定义库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bed0f3e-f11f-473f-b32b-291c80dc461b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 将上级目录加入系统路径\n",
    "# 以便导入项目自定义库\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# 自定义库\n",
    "from src.llm_client import LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70946ce9-51cb-4eee-bb74-d505d651915f",
   "metadata": {},
   "source": [
    "#### **2. 加载模型**\n",
    "\n",
    "加载大模型 API 接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076c3665-7da0-41bf-bd6d-c85226bb4bac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM API 接口加载完毕！\n"
     ]
    }
   ],
   "source": [
    "# 模型名称\n",
    "# 可选模型：\n",
    "# 大模型：kimi-k2.5 | glm-5 | deepseek-v3.2 | qwen3-max\n",
    "\n",
    "model = 'kimi-k2.5'\n",
    "\n",
    "# 采样温度系数\n",
    "# 控制生成结果的多样性\n",
    "# 取值越高，生成结果更多样\n",
    "# 反之，生成结果更确定\n",
    "# 取值范围：[0, 2)\n",
    "# 默认系数：0.1\n",
    "\n",
    "temperature = 0.1\n",
    "\n",
    "# 是否开启思考模式\n",
    "# 若开启：enable_thinking =True\n",
    "# 模型会输出完整推理过程\n",
    "# 生成更长文本，消耗更多 Token\n",
    "# 默认模式：不开启\n",
    "\n",
    "enable_thinking = False\n",
    "\n",
    "# 初始化大模型 API 接口\n",
    "# 登录阿里云百炼平台：https://bailian.console.aliyun.com/\n",
    "# 申请调用大模型服务的 API-Key\n",
    "# 并在 config 文件中设置 LLM_API_KEY=sk-********\n",
    "# 新注册用户可免费调用部分模型的 API\n",
    "# 登录后在模型服务页面查看免费模型列表\n",
    "\n",
    "client = LLMClient(\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    enable_thinking=enable_thinking,\n",
    ")\n",
    "print('LLM API 接口加载完毕！')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b682d7-6983-4d94-aaf9-8f6ab2f71199",
   "metadata": {},
   "source": [
    "#### **3. 汉语分词**\n",
    "\n",
    "大模型汉语分词：JSON 格式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb122cb-2186-4454-8f71-0a091569c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 汉语分词提示词：JSON 格式输出 ===\n",
    "\n",
    "# 可替换提示词中的中文文本\n",
    "# 测试中文分词效果\n",
    "\n",
    "prompt = \"\"\"\n",
    "\"You are a professional corpus linguist specialized in Chinese tokenization.\n",
    "\n",
    "Your task is to tokenize the given text.\n",
    "    \n",
    "Return result in a JSON list.\n",
    "\n",
    "Text: 北风如刀，满地冰霜。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfae1f1-80ca-4df1-926f-27c0bcd9c718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北风', '如', '刀', '，', '满地', '冰霜', '。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 调用大模型 API：开始分词 ===\n",
    "\n",
    "# --- 注意 ---\n",
    "# 为节省 API 调用成本\n",
    "# 大模型生成内容保存于本地缓存 data/llm_cache\n",
    "# 完成首次调用后，再次调用只需从本地数据库读取生成结果\n",
    "\n",
    "# 若需测试 API 连接是否正常\n",
    "# 可修改提示词后，重新标注\n",
    "\n",
    "# 设置 json_output=True\n",
    "# 输出 JSON 格式的分词结果\n",
    "\n",
    "client.get_response(prompt=prompt, json_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
