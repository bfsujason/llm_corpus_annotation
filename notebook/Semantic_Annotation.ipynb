{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da862f49-915f-444b-9cc1-733b3b8b91fe",
   "metadata": {},
   "source": [
    "#### **1. 设置环境**\n",
    "\n",
    "将 src 目录加入 Python 的搜索路径，以便导入语义标注模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13473d77-3806-4926-9273-5e7c5a8fda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 将上级目录加入系统路径\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.utils import load_multiver_corpus\n",
    "from src.annotator.semantic_annotation import SemanticAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6633ef8-adc8-40d3-88c2-3ae25007c1e1",
   "metadata": {},
   "source": [
    "#### **2. 读取语料**\n",
    "\n",
    "使用 src/utils.py 中的函数 load_multiver_corpus，加载多版本平行语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8775056-ae01-495c-9ac7-c552c98e5a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据文件: ../data/output/0_mt_generation.jsonl ...\n",
      "成功读取数据：共 305 条数据\n",
      "准备为 305 条数据标注语义类别\n"
     ]
    }
   ],
   "source": [
    "# 指定数据文件路径\n",
    "data_file = '../data/output/0_mt_generation.jsonl'\n",
    "\n",
    "print(f\"读取数据文件: {data_file} ...\")\n",
    "data = load_multiver_corpus(data_file)\n",
    "print(f\"成功读取数据：共 {len(data)} 条数据\")\n",
    "\n",
    "# 设置 LIMIT=10，仅读取前 10 条数据\n",
    "# 设置 LIMIT=None，读取全部数据\n",
    "#LIMIT = 5\n",
    "LIMIT = None\n",
    "if LIMIT:\n",
    "    data = data.head(LIMIT)\n",
    "print(f\"准备为 {len(data)} 条数据标注语义类别\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce1307ca-a16c-4739-bff3-083c4f8cdb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据前 5 行如下：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>北风如刀，满地冰霜。</td>\n",
       "      <td>{'human': None, 'deepseek-v3.2': 'The north wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>江南近海滨的一条大路上，一队清兵手执刀枪，押着七辆囚车，冲风冒寒，向北而行。</td>\n",
       "      <td>{'human': 'Along a coastal road somewhere sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>前面三辆囚车中分别监禁的是三个男子，都作书生打扮，一个是白发老者，两个是中年人。</td>\n",
       "      <td>{'human': 'In each of the first three carts a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>后面四辆囚车中坐的是女子，最后一辆囚车中是个少妇，怀中抱着个女婴。</td>\n",
       "      <td>{'human': 'The four rear carts were occupied b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>女婴啼哭不休。 她母亲温言相呵，女婴只是大哭。</td>\n",
       "      <td>{'human': 'The little girl was crying in a con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    source  \\\n",
       "0   0                                北风如刀，满地冰霜。   \n",
       "1   1    江南近海滨的一条大路上，一队清兵手执刀枪，押着七辆囚车，冲风冒寒，向北而行。   \n",
       "2   2  前面三辆囚车中分别监禁的是三个男子，都作书生打扮，一个是白发老者，两个是中年人。   \n",
       "3   3         后面四辆囚车中坐的是女子，最后一辆囚车中是个少妇，怀中抱着个女婴。   \n",
       "4   4                   女婴啼哭不休。 她母亲温言相呵，女婴只是大哭。   \n",
       "\n",
       "                                             targets  \n",
       "0  {'human': None, 'deepseek-v3.2': 'The north wi...  \n",
       "1  {'human': 'Along a coastal road somewhere sout...  \n",
       "2  {'human': 'In each of the first three carts a ...  \n",
       "3  {'human': 'The four rear carts were occupied b...  \n",
       "4  {'human': 'The little girl was crying in a con...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平行语料原文 source 节选自《鹿鼎记》\n",
    "# 译文 targets 包括 3 个版本：\n",
    "# human：人类译本（闵福德译）\n",
    "# deepseek-v3.2：deepseek 译本\n",
    "# qwen3-max：qwen 译本\n",
    "\n",
    "# 预览数据\n",
    "print(f\"数据前 5 行如下：\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ee1a2-9537-4e66-9044-72352320131f",
   "metadata": {},
   "source": [
    "#### **3. 加载模型**\n",
    "\n",
    "加载 src/annotator/semantic_annotation.py 中定义的语义标注模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8def1053-d9f4-4ebe-8d6d-b09d02ee74b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文语义标注模型加载完毕：glm-4.7\n",
      "英文语义标注模型加载完毕：glm-4.7\n"
     ]
    }
   ],
   "source": [
    "# 指定用于语义标注的大模型\n",
    "# 可从以下模型选取：\n",
    "# qwen-flash, qwen-plus, qwen3-max, glm-4.7, deepseek-v3.2\n",
    "model = 'glm-4.7'\n",
    "\n",
    "# 加载模型前，请登录阿里云百炼平台：https://bailian.console.aliyun.com/\n",
    "# 申请调用大模型服务的 API 账户\n",
    "# 并在 llm_corpus_annotation/.env 文件中设置 LLM_API_KEY=sk-********\n",
    "\n",
    "# 加载中文语义标注模型\n",
    "zh_annotator = SemanticAnnotator(lang='Chinese', model=model)\n",
    "print(f\"中文语义标注模型加载完毕：{zh_annotator.model}\")\n",
    "\n",
    "# 加载英文语义标注模型\n",
    "en_annotator = SemanticAnnotator(lang='English', model=model)\n",
    "print(f\"英文语义标注模型加载完毕：{en_annotator.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f6ee4-4925-4dc3-9a8c-bf5a97b6a38f",
   "metadata": {},
   "source": [
    "#### **4. 批量标注**\n",
    "\n",
    "标注中文原文和英文各译本的语义类别，并以 JSON 格式返回标注结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0a4177d-a6a4-4af2-81eb-c55b3e2e7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_data(data, zh_annotator, en_annotator):\n",
    "    results = []\n",
    "    for index, row in tqdm(data.iterrows(), total=len(data), desc=\"Semantic Tagging\"):\n",
    "        try:\n",
    "            # 解析数据\n",
    "            record_id = row['id']\n",
    "            zh_text = row['source']\n",
    "            targets_dict = row['targets'] # {'human':..., 'deepseek-v3.2':...}\n",
    "            \n",
    "            # 标注中文原文\n",
    "            if zh_text and isinstance(zh_text, str):\n",
    "                source_anno = zh_annotator.annotate(zh_text)\n",
    "            else:\n",
    "                source_anno = None\n",
    "\n",
    "            # 标注英文译文\n",
    "            target_annos = {}\n",
    "            \n",
    "            for version_name, en_text in targets_dict.items():\n",
    "                if en_text and isinstance(en_text, str):\n",
    "                    # 分别标注各版本译文\n",
    "                    en_anno = en_annotator.annotate(en_text)\n",
    "                    target_annos[version_name] = en_anno\n",
    "                else:\n",
    "                    target_annos[version_name] = None\n",
    "\n",
    "            # 合并中英文标注结果\n",
    "            record = {\n",
    "                \"id\": f\"{record_id:06d}\",\n",
    "                \"annotations\": {\n",
    "                    \"source_zh\": {\n",
    "                        \"raw_text\": zh_text,\n",
    "                        \"usas_tags\": source_anno\n",
    "                    },\n",
    "                    \"targets_en\": {\n",
    "                        ver: {\n",
    "                            \"raw_text\": txt,\n",
    "                            \"usas_tags\": tags\n",
    "                        } \n",
    "                        for ver, txt, tags in [\n",
    "                            (v, targets_dict.get(v), target_annos.get(v)) \n",
    "                            for v in targets_dict.keys()\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            results.append(record)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "968c68bc-fbb3-4a6f-a4a1-790cb88694bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Semantic Tagging: 100%|████████████████████████████████████████████████████████████| 305/305 [4:53:13<00:00, 57.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# 注意：\n",
    "# 为节省 API 调用成本，本程序将大模型生成内容保存于本地缓存 data/llm_cache\n",
    "# 完成首次调用后，再次调用只需从本地数据库读取生成结果\n",
    "# 因此，程序运行时间显示为 0.0 秒\n",
    "\n",
    "# 首次调用 API 翻译 305 句原文\n",
    "# 生成 2 个大模型译本（deepseek + qwen3-max）\n",
    "# 大约需要 20 分钟\n",
    "\n",
    "# 开始标注\n",
    "results = annotate_data(data, zh_annotator, en_annotator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a50fea-f08e-4743-816c-7f8d67c8d2c4",
   "metadata": {},
   "source": [
    "#### **5. 保存结果**\n",
    "\n",
    "将大模型译文保存于指定的文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45bf945c-92f6-4165-8a6c-4d2f9f6b2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_results 函数：\n",
    "# 将 results 列表转换为 JSON 格式\n",
    "# 保存于 out_file 文件\n",
    "def save_results(results, out_file):\n",
    "     with open(out_file, \"wt\", encoding=\"utf-8\") as fout:\n",
    "        for record in results:\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c404654-ac98-4496-af1f-361134cd4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果已保存至 ../data/output/2_semantic_annoation.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定输出文件\n",
    "out_file = '../data/output/2_semantic_annotation.jsonl'\n",
    "\n",
    "# 保存大模型译文\n",
    "save_results(results, out_file)\n",
    "print(f\"结果已保存至 {out_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b5c5d-b584-4321-9eea-5f657e73890f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
