{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fb5cd8-2ed0-4ea9-9920-dafb8d5a9445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T18:09:08.740591Z",
     "iopub.status.busy": "2026-01-17T18:09:08.740376Z",
     "iopub.status.idle": "2026-01-17T18:09:08.745757Z",
     "shell.execute_reply": "2026-01-17T18:09:08.745027Z",
     "shell.execute_reply.started": "2026-01-17T18:09:08.740574Z"
    },
    "tags": []
   },
   "source": [
    "#### **1. 导入模块**\n",
    "\n",
    "导入 Python 标准库和本项目自定义库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bed0f3e-f11f-473f-b32b-291c80dc461b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 将上级目录加入系统路径\n",
    "# 以便导入项目自定义库\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# 自定义库\n",
    "from src.llm_client import LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70946ce9-51cb-4eee-bb74-d505d651915f",
   "metadata": {},
   "source": [
    "#### **2. 加载模型**\n",
    "\n",
    "加载大模型 API 接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076c3665-7da0-41bf-bd6d-c85226bb4bac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型名称\n",
    "# 可选模型：\n",
    "# 大模型：deepseek-v3.2 | kimi-k2.5 | glm-4.7 | qwen3-max\n",
    "model = 'kimi-k2.5'\n",
    "\n",
    "# 采样温度系数\n",
    "# 控制生成结果的多样性\n",
    "# 取值越高，生成结果更多样\n",
    "# 反之，生成结果更确定\n",
    "# 取值范围：[0, 2)\n",
    "# 默认系数：0.1\n",
    "temperature = 0.1\n",
    "\n",
    "# 是否开启思考模式\n",
    "# 若开启：enable_thinking =True\n",
    "# 模型会输出完整推理过程\n",
    "# 生成更长文本，消耗更多 Token\n",
    "# 默认模式：不开启\n",
    "enable_thinking = False\n",
    "\n",
    "# 初始化大模型 API 接口\n",
    "# 登录阿里云百炼平台：https://bailian.console.aliyun.com/\n",
    "# 申请调用大模型服务的 API-Key\n",
    "# 并在 config 文件中设置 LLM_API_KEY=sk-********\n",
    "# 新注册用户可免费调用部分模型的 API\n",
    "# 登录后在模型服务页面查看免费模型列表\n",
    "client = LLMClient(\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    enable_thinking=enable_thinking,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb5d4e-4f77-41b0-8ba6-d0ddcf19dfc1",
   "metadata": {},
   "source": [
    "#### **3. 文本格式输出**\n",
    "\n",
    "大模型文本格式输出：以多语种分词为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bf7e4e-c96c-407d-9581-0454780aab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 多语种分词提示词：普通模式 ===\n",
    "\n",
    "# 可替换提示词中的中文文本\n",
    "# 测试其他语种的分词效果\n",
    "basic_prompt = \"\"\"\n",
    "You are a professional corpus linguist specialized in multilingual tokenization.\n",
    "\n",
    "Your task is to tokenize the given text.\n",
    "\n",
    "Text: 北风如刀，满地冰霜。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb9caff-77ab-4fb7-b345-8606623a7c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll tokenize this Classical Chinese text, analyzing it at multiple levels.\\n\\n## Character-level Tokenization\\n\\n```\\n北 | 风 | 如 | 刀 | ， | 满 | 地 | 冰 | 霜 | 。\\n```\\n\\n## Word/Phrase-level Tokenization (Semantic Units)\\n\\n```\\n北风 | 如 | 刀 | ， | 满地 | 冰霜 | 。\\n```\\n\\nOr with more granular analysis:\\n```\\n[北风] [如] [刀] ， [满地] [冰霜] 。\\n```\\n\\n## Detailed Analysis\\n\\n| Token | POS | Gloss |\\n|-------|-----|-------|\\n| 北风 (běifēng) | N | north wind |\\n| 如 (rú) | V/SIM | like, as |\\n| 刀 (dāo) | N | knife, blade |\\n| 满地 (mǎndì) | ADV+NP | covering the ground |\\n| 冰霜 (bīngshuāng) | N | frost and ice |\\n\\n## Structural Note\\n\\nThis is a **couplet-style** sentence (对偶句):\\n- 北风如刀 ‖ 满地冰霜\\n- Subject-Predicate ‖ Adverbial-Noun Phrase\\n\\nThe comma marks a caesura between two balanced four-character phrases, typical of Classical Chinese literary prose.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 调用大模型 API：开始分词 ===\n",
    "\n",
    "# --- 注意 ---\n",
    "# 为节省 API 调用成本\n",
    "# 大模型生成内容保存于本地缓存 data/llm_cache\n",
    "# 完成首次调用后，再次调用只需从本地数据库读取生成结果\n",
    "\n",
    "# 若需测试 API 连接是否正常\n",
    "# 可修改提示词后，重新标注\n",
    "\n",
    "# 设置 json_output=False\n",
    "# 输出文本格式的分词结果\n",
    "client.get_response(\n",
    "    prompt=basic_prompt,\n",
    "    json_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b682d7-6983-4d94-aaf9-8f6ab2f71199",
   "metadata": {},
   "source": [
    "#### **4. JSON 格式输出**\n",
    "\n",
    "大模型 JSON 格式输出：以多语种分词为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb122cb-2186-4454-8f71-0a091569c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 多语种分词提示词：JSON 模式 ===\n",
    "\n",
    "# 可替换提示词中的中文文本\n",
    "# 测试其他语种的分词效果\n",
    "json_prompt = \"\"\"\n",
    "\"You are a professional corpus linguist specialized in multilingual tokenization.\n",
    "\n",
    "Your task is to tokenize the given text.\n",
    "    \n",
    "Return result in a JSON list.\n",
    "\n",
    "Text: 北风如刀，满地冰霜。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfae1f1-80ca-4df1-926f-27c0bcd9c718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北风', '如', '刀', '，', '满地', '冰霜', '。']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 调用大模型 API：开始分词 ===\n",
    "\n",
    "# --- 注意 ---\n",
    "# 为节省 API 调用成本\n",
    "# 大模型生成内容保存于本地缓存 data/llm_cache\n",
    "# 完成首次调用后，再次调用只需从本地数据库读取生成结果\n",
    "\n",
    "# 若需测试 API 连接是否正常\n",
    "# 可修改提示词后，重新标注\n",
    "\n",
    "# 设置 json_output=True\n",
    "# 输出 JSON 格式的分词结果\n",
    "client.get_response(\n",
    "    prompt=json_prompt,\n",
    "    json_output=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
