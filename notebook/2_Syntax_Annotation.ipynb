{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. 设置环境**\n",
    "\n",
    "导入 Python 标准库、第三方库和本项目自定义库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# 第三方库\n",
    "# pip install pandas tqdm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 将上级目录加入系统路径\n",
    "# 以便导入项目自定义库\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# 自定义库\n",
    "# 大模型句法标注模块\n",
    "from src.utils import load_multiver_corpus\n",
    "from src.annotator.syntax_annotation import SyntaxAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. 读取语料**\n",
    "\n",
    "读取包含人工译文和大模型译文的多版本平行语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 C:\\2026_llm_corpus_annotation\\data\\output\\0_mt_generation.jsonl 文件读取数据 ...\n",
      "成功读取 305 条平行句对\n",
      "准备为前 10 条数据标注词性/句法结构\n",
      "数据前 5 行如下：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>北风如刀，满地冰霜。</td>\n",
       "      <td>{'human': None, 'deepseek-v3.2': 'The north wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>江南近海滨的一条大路上，一队清兵手执刀枪，押着七辆囚车，冲风冒寒，向北而行。</td>\n",
       "      <td>{'human': 'Along a coastal road somewhere sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>前面三辆囚车中分别监禁的是三个男子，都作书生打扮，一个是白发老者，两个是中年人。</td>\n",
       "      <td>{'human': 'In each of the first three carts a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>后面四辆囚车中坐的是女子，最后一辆囚车中是个少妇，怀中抱着个女婴。</td>\n",
       "      <td>{'human': 'The four rear carts were occupied b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>女婴啼哭不休。 她母亲温言相呵，女婴只是大哭。</td>\n",
       "      <td>{'human': 'The little girl was crying in a con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    source  \\\n",
       "0   0                                北风如刀，满地冰霜。   \n",
       "1   1    江南近海滨的一条大路上，一队清兵手执刀枪，押着七辆囚车，冲风冒寒，向北而行。   \n",
       "2   2  前面三辆囚车中分别监禁的是三个男子，都作书生打扮，一个是白发老者，两个是中年人。   \n",
       "3   3         后面四辆囚车中坐的是女子，最后一辆囚车中是个少妇，怀中抱着个女婴。   \n",
       "4   4                   女婴啼哭不休。 她母亲温言相呵，女婴只是大哭。   \n",
       "\n",
       "                                             targets  \n",
       "0  {'human': None, 'deepseek-v3.2': 'The north wi...  \n",
       "1  {'human': 'Along a coastal road somewhere sout...  \n",
       "2  {'human': 'In each of the first three carts a ...  \n",
       "3  {'human': 'The four rear carts were occupied b...  \n",
       "4  {'human': 'The little girl was crying in a con...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定语料库文件路径 data/output/0_mt_generation.jsonl\n",
    "# 文件为 JSON 格式\n",
    "# 包含《鹿鼎记》原文、闵福德译文以及大模型生成译文\n",
    "\n",
    "data_file = '../data/output/0_mt_generation.jsonl'\n",
    "print(f\"从 {os.path.abspath(data_file)} 文件读取数据 ...\")\n",
    "\n",
    "data = load_multiver_corpus(data_file)\n",
    "print(f\"成功读取 {len(data)} 条平行句对\")\n",
    "\n",
    "# 筛选数据：\n",
    "# 设置 LIMIT=10，仅标准前 10 条数据\n",
    "# 设置 LIMIT=None，标注全部数据\n",
    "LIMIT = 10\n",
    "#LIMIT = None\n",
    "if LIMIT:\n",
    "    data = data.head(LIMIT)\n",
    "print(f\"准备为前 {len(data)} 条数据标注词性/句法结构\")\n",
    "\n",
    "# 预览数据：\n",
    "# 导入后的数据以 DataFrame 格式存储\n",
    "# 第一列：原文\n",
    "# 第二列：多版本译文：\n",
    "# human：人类译本（闵福德译）\n",
    "# deepseek-v3.2：deepseek 译本\n",
    "# qwen3-max：qwen 译本\n",
    "\n",
    "print(\"数据前 5 行如下：\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. 加载模型**\n",
    "\n",
    "加载词性/句法标注模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载 HanLP 中文模型 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载中文模型：Electra Base\n",
      "\n",
      "加载 HanLP 英文模型 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载英文模型：ModernBERT Base\n"
     ]
    }
   ],
   "source": [
    "# 加载 HanLP 中文模型\n",
    "# hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH\n",
    "# 详见：https://hanlp.hankcs.com/docs/api/hanlp/pretrained/mtl.html\n",
    "# 首次加载需从网络下载模型至本地\n",
    "# 模型大小：504 MB\n",
    "\n",
    "print(\"加载 HanLP 中文模型 ...\")\n",
    "zh_annotator = SyntaxAnnotator(lang='Chinese', device=None)\n",
    "print(f\"成功加载中文模型：{zh_annotator.model_name}\\n\")\n",
    "\n",
    "# 加载 HanLP 英文模型\n",
    "# hanlp.pretrained.mtl.EN_TOK_LEM_POS_NER_SRL_UDEP_SDP_CON_MODERNBERT_BASE\n",
    "# 详见：https://hanlp.hankcs.com/docs/api/hanlp/pretrained/mtl.html\n",
    "# 首次加载需从网络下载模型至本地\n",
    "# 模型大小：620 MB \n",
    "\n",
    "print(\"加载 HanLP 英文模型 ...\")\n",
    "en_annotator = SyntaxAnnotator(lang='English', device=None)\n",
    "print(f\"成功加载英文模型：{en_annotator.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. 批量标注**\n",
    "\n",
    "使用 HanLP 标注中文原文和英文各译本的词汇和句法结构\n",
    "\n",
    "并以 JSON 格式返回标注结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 核心函数 annotate_data ===\n",
    "# 调用 HanLP 本地模型批量标注文本，结果保存于 results 列表\n",
    "\n",
    "# 参数 data：DataFrame 格式的数据（详见步骤 2）\n",
    "# 参数 zh_annotator：HanLP 中文标注模型接口（详见步骤 3）\n",
    "# 参数 en_annotator：HanLP 英文标注模型接口（详见步骤 3）\n",
    "\n",
    "def annotate_data(data, zh_annotator, en_annotator):\n",
    "    results = []\n",
    "\n",
    "    # 逐行遍历所有数据\n",
    "    for index, row in tqdm(data.iterrows(), total=len(data), desc=\"Syntax Tagging\"):\n",
    "        try:\n",
    "            # 解析数据\n",
    "            # 提取汉语原文和各版本译文\n",
    "            record_id = row['id']\n",
    "            zh_text = row['source']\n",
    "            targets_dict = row['targets'] # {'human': '...', 'deepseek-v3.2': '...'}\n",
    "            \n",
    "            # 标注中文原文\n",
    "            if zh_text:\n",
    "                source_anno = zh_annotator.annotate(zh_text, mode='light')\n",
    "            else:\n",
    "                source_anno = None\n",
    "            \n",
    "            # 标注英文译文\n",
    "            target_annos = {}\n",
    "            \n",
    "            # 遍历所有译本\n",
    "            for version_name, en_text in targets_dict.items():\n",
    "                if en_text and isinstance(en_text, str):\n",
    "                    # 分别标注各版本译文\n",
    "                    en_anno = en_annotator.annotate(en_text, mode='light')\n",
    "                    target_annos[version_name] = en_anno\n",
    "                else:\n",
    "                    target_annos[version_name] = None\n",
    "\n",
    "            # 合并中英文标注结果\n",
    "            record = {\n",
    "                \"id\": f\"{record_id:06d}\",\n",
    "                \"annotations\": {\n",
    "                    \"source_zh\": source_anno,\n",
    "                    \"targets_en\": target_annos\n",
    "                }\n",
    "            }\n",
    "            results.append(record)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Syntax Tagging: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# 注意：\n",
    "# 本地大模型在 GPU 上的运行速度远快于 CPU\n",
    "# 因此，HanLP 自动选用 GPU 标注语料\n",
    "\n",
    "# 可在命令行输入 nvidia-smi，查看是否配备 GPU\n",
    "# 若电脑未配备 GPU，建议使用免费 GPU 服务器\n",
    "# 如腾讯云 https://cloud.tencent.com/ 执行本程序\n",
    "\n",
    "# 使用 NVIDIA GeForce RTX 3050，4GB 显存\n",
    "# 标注 305 句原文及其 3 个英文译本\n",
    "# 大约需要 39 秒\n",
    "\n",
    "# 开始标注\n",
    "results = annotate_data(data, zh_annotator, en_annotator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. 保存结果**\n",
    "\n",
    "将 HanLP 标注结果保存于 JSON 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_results 函数：\n",
    "# 将 results 列表转换为 JSON 格式\n",
    "# 保存于 out_file 文件\n",
    "def save_results(results, out_file):\n",
    "     with open(out_file, \"wt\", encoding=\"utf-8\") as fout:\n",
    "        for record in results:\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果已保存至 ../data/output/1_syntax_annotation_limit10.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定输出文件\n",
    "if LIMIT:\n",
    "    out_file = f\"../data/output/1_syntax_annotation_limit{LIMIT}.jsonl\"\n",
    "else:\n",
    "    out_file = f\"../data/output/1_syntax_annotation.jsonl\"\n",
    "\n",
    "# 保存标注结果\n",
    "save_results(results, out_file)\n",
    "print(f\"结果已保存至 {out_file}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. 查看结果**\n",
    "\n",
    "预览中英文标注结果，查看词性/句法赋码集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ID]: 000000\n",
      "============================================================\n",
      "  【原文】:  北风如刀，满地冰霜。\n",
      "   TOK:    ['北风', '如', '刀', '，', '满地'] ...\n",
      "   POS:    ['n', 'v', 'n', 'w', 'n'] ...\n",
      "   DEP:    [(2, 'nsubj'), (0, 'root'), (2, 'dobj'), (2, 'punct'), (6, 'advmod')] ...\n",
      "------------------------------------------------------------\n",
      "【DEEPSEEK-V3.2】\n",
      "   Text:   The north wind cut like a knife, and frost covered the ground.\n",
      "   TOK:    ['The', 'north', 'wind', 'cut', 'like'] ...\n",
      "   LEM:    ['the', 'north', 'wind', 'cut', 'like'] ...\n",
      "   POS:    ['DT', 'NN', 'NN', 'VBD', 'IN'] ...\n",
      "   DEP:    [(3, 'det'), (3, 'compound'), (4, 'nsubj'), (0, 'root'), (7, 'case')] ...\n",
      "..............................\n",
      "【QWEN3-MAX】\n",
      "   Text:   The north wind cuts like a knife; ice and frost cover the ground.\n",
      "   TOK:    ['The', 'north', 'wind', 'cuts', 'like'] ...\n",
      "   LEM:    ['the', 'north', 'wind', 'cut', 'like'] ...\n",
      "   POS:    ['DT', 'NN', 'NN', 'VBZ', 'IN'] ...\n",
      "   DEP:    [(3, 'det'), (3, 'compound'), (4, 'nsubj'), (0, 'root'), (7, 'case')] ...\n",
      "..............................\n",
      "\n",
      "[ID]: 000001\n",
      "============================================================\n",
      "  【原文】:  江南近海滨的一条大路上，一队清兵手执刀枪，押着七辆囚车，冲风冒寒，向北而行。\n",
      "   TOK:    ['江南', '近', '海滨', '的', '一'] ...\n",
      "   POS:    ['ns', 'a', 's', 'u', 'm'] ...\n",
      "   DEP:    [(3, 'nn'), (3, 'dep'), (8, 'assmod'), (3, 'assm'), (6, 'nummod')] ...\n",
      "------------------------------------------------------------\n",
      "【HUMAN】\n",
      "   Text:   Along a coastal road somewhere south of the Yangtze River, a detachment of soldiers, each of them armed with a halberd, was escorting a line of seven prison carts, trudging northwards in the teeth of a bitter wind.\n",
      "   TOK:    ['Along', 'a', 'coastal', 'road', 'somewhere'] ...\n",
      "   LEM:    ['along', 'a', 'coastal', 'road', 'somewhere'] ...\n",
      "   POS:    ['IN', 'DT', 'JJ', 'NN', 'RB'] ...\n",
      "   DEP:    [(4, 'case'), (4, 'det'), (4, 'amod'), (26, 'obl'), (4, 'advmod')] ...\n",
      "..............................\n",
      "【DEEPSEEK-V3.2】\n",
      "   Text:   Along a broad road near the coast south of the Yangtze River, a troop of Qing soldiers, armed with swords and spears, escorted seven prison carts northward, braving the biting wind and cold.\n",
      "   TOK:    ['Along', 'a', 'broad', 'road', 'near'] ...\n",
      "   LEM:    ['along', 'a', 'broad', 'road', 'near'] ...\n",
      "   POS:    ['IN', 'DT', 'JJ', 'NN', 'IN'] ...\n",
      "   DEP:    [(4, 'case'), (4, 'det'), (4, 'amod'), (26, 'obl'), (7, 'case')] ...\n",
      "..............................\n",
      "【QWEN3-MAX】\n",
      "   Text:   On a major road near the coast in Jiangnan, a squad of Qing soldiers, armed with swords and spears, escorted seven prison carts northward through biting wind and bitter cold.\n",
      "   TOK:    ['On', 'a', 'major', 'road', 'near'] ...\n",
      "   LEM:    ['on', 'a', 'major', 'road', 'near'] ...\n",
      "   POS:    ['IN', 'DT', 'JJ', 'NN', 'IN'] ...\n",
      "   DEP:    [(4, 'case'), (4, 'det'), (4, 'amod'), (23, 'obl'), (7, 'case')] ...\n",
      "..............................\n",
      "\n",
      "[ID]: 000002\n",
      "============================================================\n",
      "  【原文】:  前面三辆囚车中分别监禁的是三个男子，都作书生打扮，一个是白发老者，两个是中年人。\n",
      "   TOK:    ['前面', '三', '辆', '囚车', '中'] ...\n",
      "   POS:    ['f', 'm', 'q', 'n', 'f'] ...\n",
      "   DEP:    [(4, 'nn'), (3, 'nummod'), (4, 'clf'), (5, 'lobj'), (7, 'loc')] ...\n",
      "------------------------------------------------------------\n",
      "【HUMAN】\n",
      "   Text:   In each of the first three carts a single male prisoner was caged, identifiable by his dress as a member of the scholar class.\n",
      "   TOK:    ['In', 'each', 'of', 'the', 'first'] ...\n",
      "   LEM:    ['in', 'each', 'of', 'the', '#ord#'] ...\n",
      "   POS:    ['IN', 'DT', 'IN', 'DT', 'JJ'] ...\n",
      "   DEP:    [(2, 'case'), (13, 'obl'), (7, 'case'), (7, 'det'), (7, 'amod')] ...\n",
      "..............................\n",
      "【DEEPSEEK-V3.2】\n",
      "   Text:   In the first three prison carts were confined three men, all dressed as scholars—one was an elderly man with white hair, and the other two were middle-aged.\n",
      "   TOK:    ['In', 'the', 'first', 'three', 'prison'] ...\n",
      "   LEM:    ['in', 'the', '#ord#', '#crd#', 'prison'] ...\n",
      "   POS:    ['IN', 'DT', 'JJ', 'CD', 'NN'] ...\n",
      "   DEP:    [(6, 'case'), (6, 'det'), (6, 'amod'), (6, 'nummod'), (6, 'compound')] ...\n",
      "..............................\n",
      "【QWEN3-MAX】\n",
      "   Text:   The three men imprisoned in the first three prison carts were all dressed as scholars—one was an elderly man with white hair, and the other two were middle-aged.\n",
      "   TOK:    ['The', 'three', 'men', 'imprisoned', 'in'] ...\n",
      "   LEM:    ['the', '#crd#', 'man', 'imprison', 'in'] ...\n",
      "   POS:    ['DT', 'CD', 'NNS', 'VBN', 'IN'] ...\n",
      "   DEP:    [(3, 'det'), (3, 'nummod'), (13, 'nsubj:pass'), (3, 'acl'), (10, 'case')] ...\n",
      "..............................\n"
     ]
    }
   ],
   "source": [
    "# 预览前 3 条数据\n",
    "for res in results[:3]:\n",
    "    # 提取数据\n",
    "    zh_data = res['annotations']['source_zh']\n",
    "    en_targets = res['annotations']['targets_en']\n",
    "\n",
    "    print(f\"\\n[ID]: {res['id']}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 中文\n",
    "    # 打印首句句法特征\n",
    "    zh_text = zh_data['sentences'][0]\n",
    "    zh_tokens = zh_data['tokens'][0]\n",
    "    zh_pos = zh_data['pos'][0]\n",
    "    zh_dep = zh_data['dep'][0]\n",
    "    print(f\"  【原文】:  {zh_text}\")\n",
    "    print(f\"   TOK:    {zh_tokens[:5]} ...\") \n",
    "    print(f\"   POS:    {zh_pos[:5]} ...\")\n",
    "    print(f\"   DEP:    {zh_dep[:5]} ...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # 英文\n",
    "    for version, data in en_targets.items():\n",
    "        if not data: continue\n",
    "        \n",
    "        print(f\"【{version.upper()}】\")\n",
    "        \n",
    "        # 打印各版本首句句法特征\n",
    "        sent_text = data['sentences'][0]\n",
    "        tokens = data['tokens'][0]\n",
    "        lemma = data['lem'][0]\n",
    "        pos = data['pos'][0]\n",
    "        dep = data['dep'][0]\n",
    "        \n",
    "        print(f\"   Text:   {sent_text}\")\n",
    "        print(f\"   TOK:    {tokens[:5]} ...\")\n",
    "        print(f\"   LEM:    {lemma[:5]} ...\")\n",
    "        print(f\"   POS:    {pos[:5]} ...\")\n",
    "        print(f\"   DEP:    {dep[:5]} ...\")\n",
    "        \n",
    "        print(\".\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
